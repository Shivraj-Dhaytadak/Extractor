{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "41f6a99e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import streamlit as st\n",
    "from PIL import Image\n",
    "import base64\n",
    "from io import BytesIO\n",
    "import pandas as pd\n",
    "from typing import List, Literal, TypedDict, Optional, Dict, Any\n",
    "import os\n",
    "import json\n",
    "from pydantic import BaseModel\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "from langgraph.graph import StateGraph, END\n",
    "from langchain_core.runnables import RunnableLambda\n",
    "\n",
    "# -------------------------\n",
    "# 1. LLM + Models\n",
    "# -------------------------\n",
    "gemini = ChatGoogleGenerativeAI(\n",
    "    api_key=\"AIzaSyDPaPrhk1d9JDjWH-rnE4CdEWUgkWUgO7E\",\n",
    "    model=\"gemini-2.0-flash\"\n",
    ")\n",
    "\n",
    "class Relation(BaseModel):\n",
    "    target: str\n",
    "    description: str\n",
    "\n",
    "class Service(BaseModel):\n",
    "    name: str\n",
    "    type: Literal[\"AWS service\", \"other\"]\n",
    "    description: str\n",
    "    account_context: str\n",
    "    count: int\n",
    "    relations: List[Relation]\n",
    "\n",
    "class Diagram(BaseModel):\n",
    "    services: List[Service]\n",
    "\n",
    "class PricingService(Service):\n",
    "    cost: float\n",
    "    explanation: Optional[str] = None \n",
    "\n",
    "class Cost(BaseModel):\n",
    "    cost: float\n",
    "    explanation: Optional[str] = None\n",
    "\n",
    "class PricingState(TypedDict):\n",
    "    queue: List[Service]\n",
    "    completed: List[PricingService]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "22e24d68",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_cost_lambda(config: Dict[str, Any]) -> Cost:\n",
    "    dirname = os.path.dirname(__file__)\n",
    "    json_path = os.path.join(dirname, \"lambda.json\")\n",
    "    with open(json_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        contents = f.read()\n",
    "    user_desc = config.get(\"description\", \"10 million requests per month\")\n",
    "    msg_content = [\n",
    "        {\n",
    "            \"type\": \"text\",\n",
    "            \"text\": (\n",
    "                f\"Given the AWS Lambda service with configuration: {user_desc}, \"\n",
    "                \"compute the total monthly cost while explicitly ignoring any Free Tier pricing. \"\n",
    "                \"Provide a detailed breakdown of the cost calculations.\"\n",
    "            )\n",
    "        },\n",
    "        {\n",
    "            \"type\": \"text\",\n",
    "            \"text\": f\"Use the following pricing details (JSON): {contents}\"\n",
    "        }\n",
    "    ]\n",
    "    msg_lambda = HumanMessage(content=msg_content)\n",
    "    return gemini.with_structured_output(Cost).invoke([msg_lambda])\n",
    "\n",
    "\n",
    "def compute_cost_s3(config: Dict[str, Any]) -> Cost:\n",
    "    return Cost(cost=0.0, explanation=\"S3 cost computation not implemented yet.\")\n",
    "\n",
    "\n",
    "def compute_cost_api_gateway(config: Dict[str, Any]) -> Cost:\n",
    "    return Cost(cost=0.0, explanation=\"API Gateway cost computation not implemented yet.\")\n",
    "\n",
    "\n",
    "def compute_cost(service: Service, config: Dict[str, Any]) -> Cost:\n",
    "    name = service.name.lower()\n",
    "    if \"lambda\" in name:\n",
    "        return compute_cost_lambda(config)\n",
    "    elif \"s3\" in name:\n",
    "        return compute_cost_s3(config)\n",
    "    elif \"api gateway\" in name:\n",
    "        return compute_cost_api_gateway(config)\n",
    "    else:\n",
    "        return Cost(cost=0.0, explanation=\"Service not supported.\")\n",
    "\n",
    "\n",
    "def make_cost_node(user_inputs: Dict[str, Dict[str, Any]]):\n",
    "    def cost_node(state: PricingState) -> PricingState:\n",
    "        if not state[\"queue\"]:\n",
    "            return state\n",
    "        current = state[\"queue\"][0]\n",
    "        rest = state[\"queue\"][1:]\n",
    "        config = user_inputs.get(current.name, {})\n",
    "        cost = compute_cost(current, config)\n",
    "        new = PricingService(**current.model_dump(),\n",
    "                             cost=cost.cost,\n",
    "                             explanation=cost.explanation or \"No explanation provided\")\n",
    "        return PricingState(queue=rest, completed=state[\"completed\"] + [new])\n",
    "    return cost_node\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4a9527a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-03 18:30:16.988 WARNING streamlit.runtime.scriptrunner_utils.script_run_context: Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-06-03 18:30:16.989 WARNING streamlit.runtime.scriptrunner_utils.script_run_context: Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-06-03 18:30:17.631 \n",
      "  \u001b[33m\u001b[1mWarning:\u001b[0m to view this Streamlit app on a browser, run it with the following\n",
      "  command:\n",
      "\n",
      "    streamlit run c:\\Users\\Dhaya\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\ipykernel_launcher.py [ARGUMENTS]\n",
      "2025-06-03 18:30:17.632 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-06-03 18:30:17.632 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-06-03 18:30:17.633 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-06-03 18:30:17.633 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-06-03 18:30:17.634 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-06-03 18:30:17.635 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-06-03 18:30:17.635 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-06-03 18:30:17.636 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-06-03 18:30:17.636 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'read'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\Dhaya\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\PIL\\Image.py:3511\u001b[0m, in \u001b[0;36mopen\u001b[1;34m(fp, mode, formats)\u001b[0m\n\u001b[0;32m   3510\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3511\u001b[0m     \u001b[43mfp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mseek\u001b[49m(\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m   3512\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mAttributeError\u001b[39;00m, io\u001b[38;5;241m.\u001b[39mUnsupportedOperation):\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'seek'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 10\u001b[0m\n\u001b[0;32m      7\u001b[0m     st\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease upload an architecture diagram.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      8\u001b[0m     st\u001b[38;5;241m.\u001b[39mstop()\n\u001b[1;32m---> 10\u001b[0m img \u001b[38;5;241m=\u001b[39m \u001b[43mImage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43muploaded\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     11\u001b[0m st\u001b[38;5;241m.\u001b[39mimage(img, use_container_width\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# Convert image to base64 for LLM input\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Dhaya\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\PIL\\Image.py:3513\u001b[0m, in \u001b[0;36mopen\u001b[1;34m(fp, mode, formats)\u001b[0m\n\u001b[0;32m   3511\u001b[0m     fp\u001b[38;5;241m.\u001b[39mseek(\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m   3512\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mAttributeError\u001b[39;00m, io\u001b[38;5;241m.\u001b[39mUnsupportedOperation):\n\u001b[1;32m-> 3513\u001b[0m     fp \u001b[38;5;241m=\u001b[39m io\u001b[38;5;241m.\u001b[39mBytesIO(\u001b[43mfp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m())\n\u001b[0;32m   3514\u001b[0m     exclusive_fp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m   3516\u001b[0m prefix \u001b[38;5;241m=\u001b[39m fp\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;241m16\u001b[39m)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'read'"
     ]
    }
   ],
   "source": [
    "st.set_page_config(page_title=\"AWS Arch + Cost Analyzer\", layout=\"centered\")\n",
    "st.title(\"ðŸ“Š AWS Architecture & Cost Analyzer\")\n",
    "\n",
    "# 3.1 Upload and display diagram\n",
    "uploaded = st.file_uploader(\"Upload AWS diagram (PNG/JPG)\", type=[\"png\", \"jpg\", \"jpeg\"])\n",
    "if not uploaded:\n",
    "    st.info(\"Please upload an architecture diagram.\")\n",
    "    st.stop()\n",
    "\n",
    "img = Image.open(uploaded)\n",
    "st.image(img, use_container_width=True)\n",
    "\n",
    "# Convert image to base64 for LLM input\n",
    "buffer = BytesIO()\n",
    "img.save(buffer, format=\"PNG\")\n",
    "b64 = base64.b64encode(buffer.getvalue()).decode()\n",
    "\n",
    "msg = HumanMessage(content=[\n",
    "    {\"type\": \"text\", \"text\": \"Extract all AWS services from this image.\"},\n",
    "    {\"type\": \"image_url\", \"image_url\": f\"data:image/png;base64,{b64}\"}\n",
    "])\n",
    "\n",
    "# 3.2 Extract services via Gemini\n",
    "with st.spinner(\"Extracting services...\"):\n",
    "    diagram: Diagram = gemini.with_structured_output(Diagram).invoke([msg])\n",
    "    services = [s for s in diagram.services if s.type == \"AWS service\"]\n",
    "    st.success(f\"Found {len(services)} AWS services.\")\n",
    "\n",
    "if not services:\n",
    "    st.info(\"No AWS services found in the image.\")\n",
    "    st.stop()\n",
    "\n",
    "# 3.3 Collect user inputs per service\n",
    "if 'service_inputs' not in st.session_state:\n",
    "    st.session_state.service_inputs = {}\n",
    "\n",
    "st.subheader(\"ðŸ§© Configure Detected AWS Services\")\n",
    "for service in services:\n",
    "    with st.expander(f\"Configure {service.name}\"):\n",
    "        description = st.text_area(\n",
    "            f\"{service.name} Configuration Description\",\n",
    "            key=f\"desc_{service.name}\",\n",
    "            placeholder=\"e.g. 5 million requests, 256MB memory, 500ms average duration\"\n",
    "        )\n",
    "        if st.button(f\"Save {service.name} Configuration\", key=f\"save_{service.name}\"):\n",
    "            st.session_state.service_inputs[service.name] = {\"description\": description or \"\"}\n",
    "            st.success(f\"Configuration for {service.name} saved.\")\n",
    "\n",
    "# 3.4 Once inputs are provided, run cost analysis\n",
    "\n",
    "if st.button(\"Run Cost Analysis\"):\n",
    "    # Ensure each service has a config; if missing, default to empty description\n",
    "    user_inputs: Dict[str, Dict[str, Any]] = {}\n",
    "    for s in services:\n",
    "        user_inputs[s.name] = st.session_state.service_inputs.get(s.name, {\"description\": \"\"})\n",
    "\n",
    "    # Build and run LangGraph with the cost node factory\n",
    "    cost_node_fn = make_cost_node(user_inputs)\n",
    "    graph = StateGraph(PricingState)\n",
    "    graph.add_node(\"cost\", RunnableLambda(cost_node_fn))\n",
    "    graph.set_entry_point(\"cost\")\n",
    "    graph.set_finish_point(\"cost\")\n",
    "    graph.add_conditional_edges(\"cost\", lambda s: END if not s[\"queue\"] else \"cost\")\n",
    "    cost_runner = graph.compile(debug=True)\n",
    "\n",
    "    initial_state = PricingState(queue=services, completed=[])\n",
    "    final_state = cost_runner.invoke(initial_state)\n",
    "\n",
    "    # Build DataFrame for display\n",
    "    df_state = pd.DataFrame(\n",
    "        [\n",
    "            {\n",
    "                \"Service\": s.name,\n",
    "                \"Cost (Monthly USD)\": f\"${s.cost:.2f}\",\n",
    "                \"Cost (Yearly USD)\": f\"${s.cost * 12:.2f}\",\n",
    "                \"Status\": \"Completed\",\n",
    "                \"Explanation\": s.explanation or \"No explanation provided\"\n",
    "            }\n",
    "            for s in final_state[\"completed\"]\n",
    "        ] +\n",
    "        [\n",
    "            {\n",
    "                \"Service\": s.name,\n",
    "                \"Cost (Monthly USD)\": \"\",\n",
    "                \"Cost (Yearly USD)\": \"\",\n",
    "                \"Status\": \"Pending\"\n",
    "            }\n",
    "            for s in final_state[\"queue\"]\n",
    "        ]\n",
    "    )\n",
    "    df_state.index = range(1, len(df_state) + 1)\n",
    "\n",
    "    st.subheader(\"Final State Data\")\n",
    "    st.dataframe(df_state, use_container_width=True)\n",
    "\n",
    "    if final_state[\"completed\"]:\n",
    "        st.subheader(\"Total Cost Summary\")\n",
    "        total_monthly = sum(s.cost for s in final_state[\"completed\"])\n",
    "        total_yearly = total_monthly * 12\n",
    "        total_df = pd.DataFrame({\n",
    "            \"Cost Type\": [\"Monthly Total\", \"Yearly Total\"],\n",
    "            \"Cost\": [f\"${total_monthly:.2f}\", f\"${total_yearly:.2f}\"]\n",
    "        })\n",
    "        total_df.index = range(1, len(total_df) + 1)\n",
    "        st.dataframe(total_df, use_container_width=True)\n",
    "        with st.expander(\"View Detailed Cost Breakdown\", expanded=False):\n",
    "            st.subheader(\"Extracted AWS Services\")\n",
    "            df = pd.DataFrame([\n",
    "                {\n",
    "                    \"Service\": s.name,\n",
    "                    \"Cost (Monthly USD)\": f\"${s.cost:.2f}\",\n",
    "                    \"Cost (Yearly USD)\": f\"${s.cost * 12:.2f}\",\n",
    "                }\n",
    "                for s in final_state[\"completed\"]\n",
    "            ])\n",
    "            df.index = range(1, len(df) + 1)\n",
    "            st.dataframe(df, use_container_width=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
